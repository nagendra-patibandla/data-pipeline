# Data Engineer Technical Assessment

## 1. Task description

Provided a respondent data export and a matching schema and asked to:

- Read the raw respondent data from `responses_data.json`.
- Use the metadata in `responses_schema.json` to understand variables, types, and categorical options.
- Build a data pipeline in Python (using Pandas) that:
  - Loads the respondent data into a Pandas DataFrame.
  - Exports the data to an SPSS `.sav` file.

Supporting folder: `Testdata2024/`  
- `responses_data.json` – respondent data (JSON array of records).  
- `responses_schema.json` – survey schema, including field names, types, and categorical options.

---

## 2. Solution overview

The solution is **metadata‑driven**: the schema controls how the data is typed and labeled rather than hard‑coding column logic in the code.

Main steps:

1. **Schema parsing (`extract_schema_info`)**  
   - Reads `responses_schema.json` under `data.schema`.  
   - Derives:
     - ordered list of variable names (keys + fields),
     - target Pandas dtypes for each column (numeric, text, singleChoice, dateTime),
     - list of datetime columns.

2. **Value labels (`build_value_labels`)**  
   - For each `singleChoice` field in the schema, reads the `options` block and builds `{code → label}` mappings (e.g. status codes or lastchannel options like CAWI/CAPI). 
   - These mappings are used as SPSS variable value labels in the `.sav` file.

3. **Data loading (`load_responses_to_df`)**  
   - Reads `responses_data.json` (JSON array) into a Pandas DataFrame.  
   - Applies schema‑driven dtypes:
     - numeric → nullable `Int64`,
     - text / singleChoice → `string`,
     - dateTime → `datetime64[ns]` via `pd.to_datetime`.

4. **Export to SPSS (`main`)**  
   - Reorders DataFrame columns to match schema order (keys first, then fields).  
   - Writes `responses_data.sav` using `pyreadstat.write_sav`, passing the value labels so analysts see human‑readable categories in SPSS.

The code is organised into small functions (`extract_schema_info`, `build_value_labels`, `load_responses_to_df`, `main`) for clarity and testability.

---

## 3. Project structure

```text
Technical Test/
  Testdata2024/
    responses_data.json
    responses_schema.json
    responses_data.sav       # output, generated by the script
  pipeline.py                # main pipeline implementation
  test_pipeline.py           # unit tests for core logic
  README.md
